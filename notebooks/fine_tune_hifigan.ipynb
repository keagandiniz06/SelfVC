{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-10-15 09:06:27 nemo_logging:349] /home/keagan/anaconda3/envs/vc/lib/python3.10/site-packages/megatron/core/tensor_parallel/layers.py:254: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "      def forward(\n",
      "    \n",
      "[NeMo W 2024-10-15 09:06:27 nemo_logging:349] /home/keagan/anaconda3/envs/vc/lib/python3.10/site-packages/megatron/core/tensor_parallel/layers.py:265: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "      def backward(ctx, grad_output):\n",
      "    \n",
      "[NeMo W 2024-10-15 09:06:27 nemo_logging:349] /home/keagan/anaconda3/envs/vc/lib/python3.10/site-packages/megatron/core/tensor_parallel/layers.py:325: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "      def forward(\n",
      "    \n",
      "[NeMo W 2024-10-15 09:06:27 nemo_logging:349] /home/keagan/anaconda3/envs/vc/lib/python3.10/site-packages/megatron/core/tensor_parallel/layers.py:360: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "      def backward(ctx, grad_output):\n",
      "    \n",
      "[NeMo W 2024-10-15 09:06:30 nemo_logging:349] /home/keagan/anaconda3/envs/vc/lib/python3.10/site-packages/nemo/collections/tts/modules/common.py:206: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "      @amp.autocast(False)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from nemo.collections.tts.models import HifiGanModel\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Audio to MelSpectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_mel_torchaudio(audio_path, sr=22050, n_mels=80, n_fft=1024, hop_length=256, win_length=1024):\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "\n",
    "    # Resample the audio if necessary\n",
    "    if sample_rate != sr:\n",
    "        resampler = T.Resample(orig_freq=sample_rate, new_freq=sr)\n",
    "        waveform = resampler(waveform)\n",
    "    \n",
    "    # Mel-spectrogram transformation\n",
    "    mel_spectrogram_transform = T.MelSpectrogram(\n",
    "        sample_rate=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        n_mels=n_mels\n",
    "    )\n",
    "\n",
    "    mel_spectrogram = mel_spectrogram_transform(waveform)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram.squeeze().numpy(), ref=np.max)\n",
    "    \n",
    "    return mel_spectrogram_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files_dir = '/home/keagan/Documents/projects/SelfVC/data/audios/'\n",
    "output_dir = '/home/keagan/Documents/projects/SelfVC/data/mel_spectrograms/'\n",
    "filelist_train = '/home/keagan/Documents/projects/SelfVC/data/train_filelist.txt'\n",
    "filelist_val = '/home/keagan/Documents/projects/SelfVC/data/val_filelist.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Open the filelists for writing\n",
    "train_filelist = open(filelist_train, 'w')\n",
    "val_filelist = open(filelist_val, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.95  # 95% for training, 5% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# np.save(mel_filepath, mel)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Determine whether to add the file to the training or validation set\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand() \u001b[38;5;241m<\u001b[39m train_ratio:\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mtrain_filelist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmel_filepath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43maudio_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     val_filelist\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmel_filepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "# Process the audio files and generate mel-spectrograms\n",
    "for root, dirs, files in os.walk(audio_files_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.wav'):\n",
    "            audio_path = os.path.join(root, file)\n",
    "            # mel = audio_to_mel_torchaudio(audio_path)\n",
    "            \n",
    "            # Save mel-spectrogram as .npy\n",
    "            mel_filename = file.replace('.wav', '.npy')\n",
    "            mel_filepath = os.path.join(output_dir, mel_filename)\n",
    "            # np.save(mel_filepath, mel)\n",
    "            \n",
    "            # Determine whether to add the file to the training or validation set\n",
    "            if np.random.rand() < train_ratio:\n",
    "                train_filelist.write(f\"{mel_filepath}|{audio_path}\\n\")\n",
    "            else:\n",
    "                val_filelist.write(f\"{mel_filepath}|{audio_path}\\n\")\n",
    "\n",
    "# Close the filelists\n",
    "train_filelist.close()\n",
    "val_filelist.close()\n",
    "\n",
    "print(f\"Filelist generation complete. Training filelist: {filelist_train}, Validation filelist: {filelist_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filelist.close()\n",
    "val_filelist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Text to Json Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete. JSON saved to /home/keagan/Documents/projects/SelfVC/data/val_filelist.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to convert filelist to JSON format\n",
    "def convert_txt_to_json(txt_filepath, json_filepath):\n",
    "    # json_data = {\"manifest_version\": \"1.0.0\"}\n",
    "    data = []\n",
    "    # Open and read the .txt file\n",
    "    with open(txt_filepath, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # Process each line and create a dictionary for each entry\n",
    "        for line in lines:\n",
    "            mel_filepath, audio_filepath = line.strip().split('|')\n",
    "            entry = {\n",
    "                \"audio_filepath\": audio_filepath,\n",
    "                \"mel_filepath\": mel_filepath\n",
    "                \n",
    "            }\n",
    "            data.append(entry)\n",
    "    \n",
    "    # json_data[\"files\"] = data\n",
    "    # print(json_data)\n",
    "    # Write the result to a JSON file\n",
    "    with open(json_filepath, 'w') as json_file:\n",
    "        json.dump(data, json_file,indent=4)\n",
    "\n",
    "# Example usage\n",
    "txt_file = \"/home/keagan/Documents/projects/SelfVC/data/val_filelist.txt\"  # Replace with your .txt file path\n",
    "json_file = '/home/keagan/Documents/projects/SelfVC/data/val_filelist.json'  # Replace with your desired output path\n",
    "convert_txt_to_json(txt_file, json_file)\n",
    "\n",
    "print(f\"Conversion complete. JSON saved to {json_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting into proper Json Dataset Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train manifest saved with 93200 samples.\n",
      "Validation manifest saved with 23300 samples.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import librosa\n",
    "\n",
    "# Set paths to directories containing audio and mel spectrograms\n",
    "mel_dir = \"/home/keagan/Documents/projects/SelfVC/data/mel_spectrograms\"\n",
    "audio_dir = \"/home/keagan/Documents/projects/SelfVC/data/audios\"\n",
    "\n",
    "# Function to calculate duration of audio\n",
    "def get_audio_duration(audio_path):\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    return librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "# List all mel and audio files\n",
    "mel_files = sorted([f for f in os.listdir(mel_dir) if f.endswith('.npy')])\n",
    "audio_files = sorted([f for f in os.listdir(audio_dir) if f.endswith('.wav')])\n",
    "\n",
    "# Pair mel spectrograms and audio files\n",
    "paired_data = []\n",
    "for mel_file in mel_files:\n",
    "    base_name = os.path.splitext(mel_file)[0]\n",
    "    audio_file = base_name + \".wav\"\n",
    "    audio_path = os.path.join(audio_dir, audio_file)\n",
    "\n",
    "    if os.path.exists(audio_path):\n",
    "        mel_path = os.path.join(mel_dir, mel_file)\n",
    "        duration = get_audio_duration(audio_path)\n",
    "        \n",
    "        entry = {\n",
    "            \"audio_filepath\": audio_path,\n",
    "            \"mel_filepath\": mel_path,\n",
    "            \"text\": f\"Placeholder text for {base_name}\",\n",
    "            \"duration\": duration\n",
    "        }\n",
    "        paired_data.append(entry)\n",
    "\n",
    "# Shuffle and split into training and validation sets (80% train, 20% validation)\n",
    "random.shuffle(paired_data)\n",
    "split_idx = int(0.8 * len(paired_data))\n",
    "\n",
    "train_data = paired_data[:split_idx]\n",
    "val_data = paired_data[split_idx:]\n",
    "\n",
    "# Write the train_manifest.json and val_manifest.json\n",
    "with open('train_manifest.json', 'w') as train_file:\n",
    "    json.dump(train_data, train_file, indent=4)\n",
    "\n",
    "with open('val_manifest.json', 'w') as val_file:\n",
    "    json.dump(val_data, val_file, indent=4)\n",
    "\n",
    "print(f\"Train manifest saved with {len(train_data)} samples.\")\n",
    "print(f\"Validation manifest saved with {len(val_data)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in line 1: Expecting value: line 1 column 2 (char 1)\n",
      "Line content: [\n",
      "Manifest validated successfully if no errors!\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# # Path to your JSON manifest file\n",
    "# manifest_path = \"/home/keagan/Documents/projects/SelfVC/data/val_manifest.json\"  # or \"val_manifest.json\"\n",
    "\n",
    "# try:\n",
    "#     with open(manifest_path, 'r') as f:\n",
    "#         lines = f.readlines()\n",
    "#         for idx, line in enumerate(lines):\n",
    "#             line = line.strip()\n",
    "#             if not line:\n",
    "#                 print(f\"Empty line at index {idx + 1}\")\n",
    "#             try:\n",
    "#                 json.loads(line)\n",
    "#             except json.JSONDecodeError as e:\n",
    "#                 print(f\"Error in line {idx + 1}: {e}\")\n",
    "#                 print(f\"Line content: {line}\")\n",
    "#                 break\n",
    "#         print(\"Manifest validated successfully if no errors!\")\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Manifest file not found: {manifest_path}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the original array-style manifest\n",
    "with open(\"/home/keagan/Documents/projects/SelfVC/data/train_manifest.json\", 'r') as f:\n",
    "    data = json.load(f)  # This reads the whole file as a JSON array\n",
    "\n",
    "# Open the output file to write each entry as a separate line\n",
    "with open(\"/home/keagan/Documents/projects/SelfVC/data/train_manifest_fixed.json\", 'w') as outfile:\n",
    "    for entry in data:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')  # Write each JSON object to a new line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
